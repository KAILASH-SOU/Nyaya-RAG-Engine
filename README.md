<img width="1153" height="627" alt="image" src="https://github.com/user-attachments/assets/e743ff04-d4f2-4dd2-b01b-5d9111c28b44" />

# âš–ï¸ Nyaya RAG Engine

**Nyaya RAG Engine** is a specialized Retrieval-Augmented Generation system designed for the legal domain. It automates the ingestion, indexing, and retrieval of legal documents (case files, statutes, contracts) to provide accurate, context-aware answers with citations.

This project implements a complete end-to-end LLM pipeline, moving from raw data ingestion to a production-ready UI.


---

## ğŸš€ Key Features

* **Legal Data Ingestion:** Parsers for PDF, DOCX, and TXT legal texts.
* **Semantic Search:** Vector-based retrieval to find relevant case laws and clauses.
* **Citations:** The generation layer references specific source documents to minimize hallucinations.
* **Evaluation Loop:** Automated testing for answer faithfulness and context relevancy.
* **Containerized Deployment:** Docker support for easy productionisation.

---

## ğŸ› ï¸ Tech Stack

* **Language:** Python 3.10+
* **Orchestration:** LangChain / LlamaIndex
* **LLM:** OpenAI GPT-4 / Llama 3 (via Groq or Ollama)
* **Vector Database:** ChromaDB / Pinecone / Qdrant
* **Backend API:** FastAPI
* **Frontend:** Streamlit / React
* **Containerization:** Docker

---

## ğŸ“‚ Repository Structure

```bash
Nyaya-RAG-Engine/
â”œâ”€â”€ data/                   # Raw legal documents for ingestion
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/          # Step 1 & 2: Data loading & Vector indexing
â”‚   â”œâ”€â”€ retrieval/          # Step 3: Semantic search logic
â”‚   â”œâ”€â”€ generation/         # Step 4: LLM Prompting & Answer formulation
â”‚   â”œâ”€â”€ orchestration/      # Step 5: Chains and Agent logic
â”‚   â””â”€â”€ evaluation/         # Step 6: RAGAS/TruLens eval scripts
â”œâ”€â”€ ui/                     # Step 8: Frontend application
â”œâ”€â”€ docker-compose.yml      # Step 7: Deployment config
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md
